%!TEX TS-program = xelatex
\documentclass{beamer}

\usepackage{HSE-theme/beamerthemeHSE} % Подгружаем тему

%%% Работа с русским языком и шрифтами
\usepackage[english,russian]{babel}   % загружает пакет многоязыковой вёрстки
\usepackage{fontspec}      % подготавливает загрузку шрифтов Open Type, True Type и др.
\defaultfontfeatures{Ligatures={TeX},Renderer=Basic}  % свойства шрифтов по умолчанию
\setmainfont[Ligatures={TeX,Historic}]{Myriad Pro} %  установите шрифты Myriad Pro или (при невозможности) замените здесь на другой шрифт, который есть в системе — например, Arial
\setsansfont{Myriad Pro}  %  установите шрифты Myriad Pro или (при невозможности) замените здесь на другой шрифт, который есть в системе — например, Arial
\setmonofont{Courier New}
\uselanguage{russian}
\languagepath{russian}
\deftranslation[to=russian]{Theorem}{Теорема}
\deftranslation[to=russian]{Definition}{Определение}
\deftranslation[to=russian]{Definitions}{Определения}
\deftranslation[to=russian]{Corollary}{Следствие}
\deftranslation[to=russian]{Fact}{Факт}
\deftranslation[to=russian]{Example}{Пример}
\deftranslation[to=russian]{Examples}{Примеры}

\usepackage{alltt}
\usepackage{multicol} 		% Несколько колонок
\graphicspath{{images/}}  	% Папка с картинками

\newfontfamily\dgmk[]{DejaVu Sans}
\newfontfamily\qgmk[Scale=MatchLowercase,Letters=SmallCaps]{Linux Libertine O}

%%% Информация об авторе и выступлении
\title[Disambiguation]{Morphological disambiguation} 
%\subtitle{Подзаголовок презентации / Название конференции}
\author[Francis M. Tyers]{Francis M. Tyers\\ \smallskip \scriptsize \url{ftyers@hse.ru}\\\url{https://www.hse.ru/org/persons/209454856}}
\institute[Высшая школа экономики]{Национальный исследовательский университет \\ «Высшая школа экономики» (Москва)}
\date{\today}

\begin{document}	% Начало презентации

\frame[plain]{\titlepage}	% Титульный слайд

\section{Просто слайд с текстом}
\subsection{Просто слайд с текстом}

\begin{frame}{Introduction}

% Orientation
% Tagsets 



\end{frame}

\begin{frame}{Pipeline}

\begin{onlyenv}<1>
\includegraphics[width=\textwidth]{images/pipeline.eps}
\end{onlyenv}
\begin{onlyenv}<2>
\includegraphics[width=\textwidth]{images/pipeline-4.eps}
\end{onlyenv}

\end{frame}

\begin{frame}{Applications}
% aside from being a stage in the pipeline, what can use POS tagging directly ? 

\begin{itemize}
  \item \textbf{Speech synthesis}: How to pronounce a word in context, e.g. 
  \item \textbf{Disambiguation of meaning}:
  \item \textbf{Features for parsing}:

\end{itemize}

% shallow syntactic representation

\end{frame}

\begin{frame}{Terminology}

% Part-of-speech tagging
% Morphological disambiguation
% Morphological analysis (~parsing)

\textbf{Part-of-speech tagging:}
   \begin{itemize}
     \item Traditional term, based on approach(es) for English, finite-set of 
       tags for all combinations of lexical category and morphology. \\ ~ \\
       \begin{tabular}{llllp{0.32\textwidth}}
         \hline
         \textbf{In:} & This & is & a & test \\
         ~ & This/PRON & is/VERB & a/DET & test/NOUN \\
         \hline
       \end{tabular}
   \end{itemize}
~\\
\textbf{Morphological disambiguation:}
   \begin{itemize}
      \item More cross-linguistically applicable, conception is of disambiguating
        after morphological analysis. \\  ~ \\
       \begin{tabular}{lllll}
         \hline
         \textbf{In:} & This/DET/PRON & is/VERB & a/DET & test/VERB/NOUN \\
         ~ & This/PRON & is/VERB & a/DET & test/NOUN \\
         \hline
       \end{tabular}
   \end{itemize}  

\end{frame}

\begin{frame}{What is a tagset?}

\end{frame}

\begin{frame}{Example tagsets}

%Penn Treebank style:
%Positional style:
%Universal Dependencies:
  
\begin{onlyenv}<1>
\begin{center}
\textbf{Penn Treebank} 
\end{center}
  \begin{columns}
  
    \begin{column}{0.4\textwidth}
    
    \begin{alltt}
       This/DT \\
       tagset/NNS  \\
       contains/VBZ \\
       48/CD \\
       unique/JJ \\
       tags/NNP  \\
       ./.  \\
    \end{alltt}
    
    \end{column}
    
    \begin{column}{0.6\textwidth}
    
    \begin{itemize}
       \item 48 tags 
       \item Tags are atomic
       \item Principles have been applied to other languages (Chinese, Bengali, \ldots)
       \item Extensible ? 
    \end{itemize}
    \end{column}

  \end{columns}
  
\end{onlyenv}

\begin{onlyenv}<2>
  \begin{center}
  \includegraphics[width=0.9\textwidth]{images/penn-tagset.png}
  \end{center}
\end{onlyenv}

\begin{onlyenv}<3>
\begin{center}
\textbf{Positional tags} 
\end{center}

\end{onlyenv}

\begin{onlyenv}<4>
\begin{center}
\textbf{Mnemonic tags} 
\end{center}

\end{onlyenv}

\begin{onlyenv}<5>
\begin{center}
\textbf{Feature/value pairs} 
\end{center}
\begin{center}
\scalebox{0.7}{
\begin{tabular}{llllllllll}
1  & Польша & \_& PROPN & \_& Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing & \_& \_& \_& \_ \\
2  & является & \_& VERB & \_& Aspect=Imp|Number=Sing|Person=3|Tense=Pres & \_& \_& \_& \_ \\
3  & безъядерной & \_& ADJ & \_& Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing & \_& \_& \_& \_ \\
4  & страной & \_& NOUN & \_& Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing & \_& \_& \_& \_ \\
5  & . & \_& PUNCT & \_& \_& \_& \_& \_& \_ \\
\end{tabular}
}
\end{center}

\begin{itemize}
 \item +/-
\end{itemize}

\end{onlyenv}

\end{frame}

% Tagset considerations morph<-->syntax

\begin{frame}{Tagset design}

% Ambiguity
% 
% Morphological complexity % Language complexity tagging eng vs. chukchi

\end{frame}

\begin{frame}

They finished catching reindeer.

ӄорагыркиплыткогъат
ӄора-гырки-плыткогъат
reindeer-catch-finish-{\sc pl3}

\end{frame}

\begin{frame}{Scale of the problem}
% scale of the problem (how many words are ambiguous?) types/tokens

%UD_Arabic	28.028665680809915 26373 7392 | 69.72739248682645 282384 26373
%UD_Basque	11.47344353236628 26679 3061 | 38.47978063783009 121443 26679
%UD_Catalan	8.31324959596246 35269 2932 | 66.49986559417712 531971 35269
%UD_Czech	18.095502113798602 144290 26110 | 47.17003300400137 1506484 144290
%UD_English	14.200772535914242 23041 3272 | 52.3405891794105 254829 23041
%UD_Erzya	9.736123748862601 1099 107 | 41.37931034482759 2001 1099
%UD_Finnish	3.460714099011972 57387 1986 | 18.091922833148473 201952 57387
%UD_German	20.17361442335209 52415 10574 | 56.528450943344566 292152 52415
%UD_Hebrew	15.560653536257835 17872 2781 | 71.62094330385638 161369 17872
%UD_Hindi	36.2884775374376 19232 6979 | 86.84376634897527 351704 19232
%UD_Irish	11.885844008431977 6167 733 | 43.5778668002003 23964 6167
%UD_Japanese	1.488317951276295 24054 358 | 21.677209237334136 186071 24054
%UD_Kazakh	5.49213870342451 4643 255 | 14.739939255884584 10536 4643
%UD_Korean	0.07787295583490933 35956 28 | 8.918388207445664 74352 35956
%UD_Kurmanji	9.357118815213733 2971 278 | 36.72514619883041 10260 2971
%UD_Latin	16.095792386222687 10481 1687 | 61.373464204818454 29138 10481
%UD_Latvian	6.842492746091551 23091 1580 | 19.42334521779569 90314 23091
%UD_Lithuanian	4.405104981473857 2429 107 | 15.814040328603435 5356 2429
%UD_Norwegian-Nynorsk	8.280614214856396 33669 2788 | 43.78652278225204 301353 33669
%UD_Persian	8.810746740418807 15186 1338 | 36.46678001569448 152920 15186
%UD_Portuguese	13.192239858906527 28350 3740 | 64.51148416098897 227792 28350
%UD_Russian-SynTagRus	13.502656781952973 125716 16975 | 40.9461209547306 1105736 125716
%UD_Turkish	4.293419633225459 18540 796 | 17.44324147546345 58097 18540


\end{frame}

\begin{frame}{Types of ambiguity}
% Morphological ambiguity ... types

\begin{itemize}
  \item Intraparadigmatic
  \item Morphosyntactically incongruent
  \item Morphosyntactically congruent
\end{itemize}

\end{frame}

\begin{frame}{A baseline}
% most freq. class baseline

\end{frame}

% what POS tagging is not... tokenisation/multiwords

% Applications


\begin{frame}{Approaches}
% Approaches

\begin{itemize}
   \item \textbf{Rule-based}:
   \item \textbf{HMM-based}:
   \item \textbf{Averaged perceptron}:
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Rule-based ... CG, ...
\begin{frame}
\centering
{\LARGE {\bf Rule-based } }
\end{frame}

\begin{frame}{Constraint Grammar}

    \begin{itemize}
      \item Developed by Fred Karlsson\footnote{The same Fred Karlsson that wrote ``Finsk grammatik''.} in the late 1980s
      \item Does not aim at producing a full ``parse tree''
      \item Describes what is \emph{ungrammatical}, not what is grammatical
      \item Linguists formalise ``constraints'' which describe language impossibilities
      \begin{itemize}
        \item e.g. ``No noun can be in prepositional case without a preposition which 
          governs the prepositional case.''
      \end{itemize}
      \item No ``encapsulation'', all parts of the analysis (surface form $\rightarrow$ semantics) are always available
      \item Input is all possible analyses, output is only possible analyses
    \end{itemize}

\end{frame}

\begin{frame}{Formalism}

\begin{columns}
\column{.45\textwidth}
   \textbf{Input:}
\begin{tiny}
\begin{alltt}
"<Польша>"\\
~~~~"Польша" np top f sg nom\\
"<является>"\\
~~~~"являться" v impf iv pres p3 sg\\
"<безъядерной>"\\
~~~~"безъядерный" adj f an sg gen\\
~~~~"безъядерный" adj f an sg dat\\
~~~~"безъядерный" adj f an sg prp\\
~~~~"безъядерный" adj f an sg ins\\
"<страной>"\\
~~~~"страна" n f nn sg ins\\
"<.>"\\
~~~~"." sent\\
\end{alltt}
\end{tiny}

\column{.55\textwidth}
   \textbf{Operators:}
     \begin{itemize}
       \item {\sc select}: \dgmk{Discard all readings except the reading matching a condition}
       \item {\sc remove}: \dgmk{Discard a single reading matching a condition}
     \end{itemize}
\end{columns}

~\\
~\\
\noindent
   \textbf{Context conditions:}
     \begin{itemize}
       \item \dgmk{(-1 pres)} $\rightarrow$ previous token has the tag \qgmk{pres} 
       \item \dgmk{(1C ins)} $\rightarrow$ following token \emph{only} has the tag \qgmk{ins}
       \item \dgmk{(NOT -1* pr)} $\rightarrow$ no token to the left has the tag \qgmk{pr}
     \end{itemize}


\end{frame}

\begin{frame}{Basic example}

\begin{columns}
\column{.45\textwidth}
   \textbf{Input:}
\begin{tiny}
\begin{alltt}
"<Польша>"\\
~~~~"Польша" np top f sg nom\\
"<является>"\\
~~~~"являться" v impf iv pres p3 sg\\
"<безъядерной>"\\
\alert<3-4>{~~~~"безъядерный" adj f an sg gen}\\
\alert<4>{~~~~"безъядерный" adj f an sg dat}\\
\alert<2-4>{~~~~"безъядерный" adj f an sg prp}\\
~~~~"безъядерный" adj f an sg ins\\
"<страной>"\\
~~~~"страна" n f nn sg ins\\
"<.>"\\
~~~~"." sent\\
\end{alltt}
\end{tiny}

\column{.55\textwidth}
\begin{onlyenv}<2>
\begin{itemize}
  \item[1] \qgmk{remove} \dgmk{prp} \qgmk{if} \dgmk{(not -1* pr)}
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<3->
\begin{itemize}
  \item[1] \qgmk{remove} \dgmk{prp} \qgmk{if} \dgmk{(not -1* pr)}
  \item[2] \qgmk{remove} \dgmk{gen} \qgmk{if} \dgmk{(-1 pres) (0C adj) (not 1 gen)}
\end{itemize}
\end{onlyenv}

\end{columns}

\begin{onlyenv}<4>
~\\
~\\
Exercise: Can we safely remove the dative reading?
\end{onlyenv}

\end{frame}

\begin{frame}{Less basic example}

 \begin{large}
 « Для соседних с Руандой государств руандийские события апреля – июля 1994 года вылились в огромное число прибывших беженцев . »
 \end{large}
 % russian example

\end{frame}

\begin{frame}
  \frametitle{Standard trigram taggers}

    \begin{tiny}
        \begin{tabular}{ll}
        Для & PR  \\
        соседних & A=pl,gen,plen  \\
        с & PR  \\
        Руандой & S,f,inan=sg,ins  \\
        государств & S,n,inan=pl,gen  \\
        руандийские & \alert<2>{A=pl,acc,inan,plen}  \\
        события & \alert<2>{S,n,inan=pl,acc}  \\
        апреля & S,m,inan=sg,gen  \\
        – & –  \\
        июля & S,m,inan=sg,gen  \\
        1994 & NUM=ciph  \\
        года & S,m,inan=sg,gen  \\
        вылились & V,pf,intr,med=pl,praet,indic  \\
        в & PR  \\
        огромное & A=n,sg,acc,inan,plen  \\
        число & S,n,inan=sg,acc  \\
        прибывших & V,pf,intr,act=partcp,pl,gen,praet,plen  \\
        беженцев & S,m,anim=pl,gen  \\
        . & .  \\
        \end{tabular}
    \end{tiny}

    \begin{onlyenv}<1>
    ~\\
    ~\\
    \end{onlyenv}
    \begin{onlyenv}<2>
    ~\\
    \begin{flushright}
    2 / 19 = 89.5\% accuracy
    \end{flushright}
    \end{onlyenv}
    
\end{frame}

\begin{frame}{Input: Morphological analysis}

  \begin{flushright}
    \begin{tiny}
      \begin{onlyenv}<1>
        rule: --
      \end{onlyenv}
      \begin{onlyenv}<2>
        rule: 1
      \end{onlyenv}
      \begin{onlyenv}<3>
        rule: 2
      \end{onlyenv}
      \begin{onlyenv}<4>
        rule: 3
      \end{onlyenv}
      \begin{onlyenv}<5>
        rule: 4
      \end{onlyenv}
      \begin{onlyenv}<6-7>
        rule: 5
      \end{onlyenv}
    \end{tiny}
  \end{flushright}
\vspace{-40.0pt}
\begin{columns}
\column{.45\textwidth}
  \begin{tiny}
     \begin{alltt}
"<Для>"\\
\alert<2>{~~~"для" pr}
~\\
"<соседних>"\\
\alert<2>{~~~"соседний" adj mfn an pl gen} \\
\begin{onlyenv}<1>
~~~"соседний" adj mfn an pl prp\\
~~~"соседний" adj mfn aa pl acc
\end{onlyenv}
\begin{onlyenv}<2->
\textcolor{lightgray}{
~~~"соседний" adj mfn an pl prp\\
~~~"соседний" adj mfn aa pl acc
}
\end{onlyenv}
~\\
"<с>"\\
~~~"с" pr
~\\
"<Руандой>"\\
~~~"Руанда" np top f sg ins
~\\
"<государств>"\\
~~~"государство" n nt nn pl gen
~\\
"<руандийские>"\\
\alert<5>{~~~"руандийский" adj mfn an pl nom}\\
\begin{onlyenv}<1-4>
~~~"руандийский" adj mfn nn pl acc
\end{onlyenv}
\begin{onlyenv}<5->
\textcolor{lightgray}{
~~~"руандийский" adj mfn nn pl acc
}
\end{onlyenv}
~\\
"<события>"\\
\begin{onlyenv}<1-4>
~~~"событие" n nt nn sg gen\\
\end{onlyenv}
\begin{onlyenv}<5->
\textcolor{lightgray}{
~~~"событие" n nt nn sg gen\\
}
\end{onlyenv}
\alert<5>{~~~"событие" n nt nn pl nom}\\
\begin{onlyenv}<1-3>
~~~"событие" n nt nn pl acc
\end{onlyenv}
\begin{onlyenv}<4->
\textcolor{lightgray}{
~~~"событие" n nt nn pl acc
}
\end{onlyenv}
~\\
"<апреля>"\\
~~~"апрель" n m nn sg gen
~\\
"<–>"\\
~~~"–" guio
~\\
"<июля>"\\
~~~"июль" n m nn sg gen
~\\
    \end{alltt}
  \end{tiny}
  \column{.55\textwidth}
    \begin{tiny}
      \begin{alltt}
    "<1994>"\\
    ~~~"1994" num
    ~\\
    "<года>"\\
    ~~~"год" n m nn sg gen\\
    "<вылились>"\\
    \alert<4,5>{~~~"вылиться" v perf iv past mfn pl}
    ~\\
    "<в>"\\
    \alert<3>{~~~"в" pr}
    ~\\
    "<огромное>"\\
    \begin{onlyenv}<1-2>
    ~~~"огромный" adj nt an sg nom\\
    \end{onlyenv}
    \begin{onlyenv}<3->
    \textcolor{lightgray}{
    ~~~"огромный" adj nt an sg nom\\
    }
    \end{onlyenv}
    \alert<3>{~~~"огромный" adj nt an sg acc}
    ~\\
    "<число>"\\
    \alert<3,6>{~~~"число" n nt nn sg acc}\\
    \begin{onlyenv}<1-2>
    ~~~"число" n nt nn sg nom
    \end{onlyenv}
    \begin{onlyenv}<3->
    \textcolor{lightgray}{
    ~~~"число" n nt nn sg nom
    }
    \end{onlyenv}
    ~\\
    "<прибывших>"\\
    \begin{onlyenv}<1-3>
    ~~~"прибыть" v perf iv pp actv mfn an pl acc  \\
    \end{onlyenv}
    \begin{onlyenv}<4->
    \textcolor{lightgray}{
    ~~~"прибыть" v perf iv pp actv mfn an pl acc  \\
    }
    \end{onlyenv}
    \begin{onlyenv}<1-6>
    \alert<6>{~~~"прибыть" v perf iv pp actv mfn an pl prp} \\
    \end{onlyenv}
    \begin{onlyenv}<7->
    \textcolor{lightgray}{
    ~~~"прибыть" v perf iv pp actv mfn an pl prp \\
    }
    \end{onlyenv}
    \begin{onlyenv}<1-7>
    ~~~"прибыть" v perf iv pp actv mfn aa pl gen
    \end{onlyenv}
    ~\\
    "<беженцев>"\\
    \alert<4>{~~~"беженец" n m aa pl gen}\\
    \begin{onlyenv}<1-3>
    ~~~"беженец" n m aa pl acc
    \end{onlyenv}
    \begin{onlyenv}<4->
    \textcolor{lightgray}{
    ~~~"беженец" n m aa pl acc
    }
    \end{onlyenv}
    ~\\
    "<.>"\\
    ~~~"." sent
    \end{alltt}
    \end{tiny}

    \end{columns}
%!%
\end{frame}

\begin{frame}
  \frametitle{Proposed rule (I)}

  \begin{itemize}
    \item[1] Immediately after ``для'' remove any reading which is in a case other 
       than genitive.
  \end{itemize}
~\\
\textbf{Exceptions:}
  \begin{itemize}
    \item None ? 
  \end{itemize}
~\\
\textbf{Formalised:}

{\small
\begin{alltt}
  LIST Gen = gen ; \\
  SET NGDAIP = nom OR gen OR dat OR acc OR ins OR prp ;  \\
  REMOVE NGDAIP - Gen IF (-1C ("для")) ; \\
\end{alltt}
}
\end{frame}

\begin{frame}
  \frametitle{Proposed rule (II)}
 
  \begin{itemize}
    \item[2] After ``в'' remove any reading which is in nominative % certain constructions allow this ?

  \end{itemize}

~\\
\textbf{Exceptions:}
  \begin{itemize}
    \item Joining an organisation ?
  \end{itemize}

~\\
\textbf{Formalised:}
{\small
\begin{alltt}
  LIST Nom = nom ; \\
  REMOVE Nom IF (-1C ("в")) ;
\end{alltt}
}
\end{frame}

\begin{frame}
  \frametitle{Proposed rule (III)}

  \begin{itemize}
    \item[3] In a sentence with a single intransitive finite verb, remove any reading in accusative which is not
       immediately governed by a preposition % or transitive participle form or some adverbial forms ?
  \end{itemize}

~\\
\textbf{Exceptions:}
  \begin{itemize}
    \item There is a trans. part. form having an acc. arg.
    \item Some adverbial forms... \emph{Мы проехали километр.}
  \end{itemize}

~\\
\textbf{Formalised:}
{\small
  \begin{alltt}
  LIST IV = iv ; \\
  LIST TV = tv ; \\
  LIST Acc = acc ; \\
  LIST Pr = pr ; \\
  REMOVE Acc IF (0 Acc LINK NOT -1* Pr) ((-1* IV) OR (1* IV)) (0 Acc LINK NOT 1* TV) (0 Acc LINK NOT -1* TV) ; 
  \end{alltt}
}
\end{frame}
  
\begin{frame}
  \frametitle{Proposed rule (IV)}

  \begin{itemize}
    \item[4] Select nominative if there is an intransitive verb which agrees with a nominative noun in the sentence 
       for number (and/or gender)
     \begin{itemize}
        \item and is preceeded by an adj. that can only be nom.
        \item and there is no other nom. head in the sentence.
     \end{itemize}
  \end{itemize}
~\\
\textbf{Exceptions:}
  \begin{itemize}
    \item Appositions, titles, parentheticals ? Non-canonical agreement ?
  \end{itemize}
~\\
\textbf{Formalised:}
{\small
  \begin{alltt}
    LIST Head = np n prn ;\\
    SET NUM = (sg) OR (pl) ; \\
    SELECT Nom + \$\$NUM IF (-1C A + Nom) (NOT -1* Head + Nom) (NOT 1* Head + Nom) ((-1* V + \$\$NUM) OR (1* V + \$\$NUM));
  \end{alltt}
}
\end{frame}

\begin{frame}
  \frametitle{Proposed rule (V)}

  \begin{itemize}
    \item[5] If there is a prepositional case reading, remove it if you see a
       noun which is only in a case other than prepositional without any preceeding transitive participle form
  \end{itemize}
~\\
\textbf{Exceptions:}
  \begin{itemize}
    \item ...
  \end{itemize}

~\\
\textbf{Formalised:}
{\small
  \begin{alltt}
    LIST Prp = prp ; \\
    LIST N = n ;\\
    REMOVE Prp IF (-1* N + NGDAIP - Prp) ;\\
  \end{alltt}
}

\end{frame}

\begin{frame}
    \frametitle{Output: Morphologically-disambiguated text}

\begin{columns}
\column{.45\textwidth}
\begin{tiny}
\begin{alltt}
"<Для>"\\
~~~"для" pr
~\\
"<соседних>"\\
~~~"соседний" adj mfn an pl gen\\
\textcolor{lightgray}{
~~~"соседний" adj mfn an pl prp\\
~~~"соседний" adj mfn aa pl acc
}
~\\
"<с>"\\
~~~"с" pr
~\\
"<Руандой>"\\
~~~"Руанда" np top f sg ins
~\\
"<государств>"\\
~~~"государство" n nt nn pl gen
~\\
"<руандийские>"\\
~~~"руандийский" adj mfn an pl nom\\
\textcolor{lightgray}{
~~~"руандийский" adj mfn nn pl acc
}

~\\
"<события>"\\
\textcolor{lightgray}{
~~~"событие" n nt nn sg gen\\
}
~~~"событие" n nt nn pl nom\\
\textcolor{lightgray}{
~~~"событие" n nt nn pl acc
}

~\\
"<апреля>"\\
~~~"апрель" n m nn sg gen
~\\
"<–>"\\
~~~"–" guio
~\\
"<июля>"\\
~~~"июль" n m nn sg gen
~\\
\end{alltt}
\end{tiny}
\column{.55\textwidth}
\begin{tiny}
\begin{alltt}
"<1994>"\\
~~~"1994" num
~\\
"<года>"\\
~~~"год" n m nn sg gen\\
"<вылились>"\\
~~~"вылиться" v perf iv past mfn pl
~\\
"<в>"\\
~~~"в" pr
~\\
"<огромное>"\\
\textcolor{lightgray}{
~~~"огромный" adj nt an sg nom\\
}
~~~"огромный" adj nt an sg acc
~\\
"<число>"\\
~~~"число" n nt nn sg acc\\
\textcolor{lightgray}{
~~~"число" n nt nn sg nom
}

~\\
"<прибывших>"\\
\textcolor{lightgray}{
~~~"прибыть" v perf iv pp actv mfn an pl acc  \\
~~~"прибыть" v perf iv pp actv mfn an pl prp \\
}
~~~"прибыть" v perf iv pp actv mfn aa pl gen
~\\
"<беженцев>"\\
~~~"беженец" n m aa pl gen\\
\textcolor{lightgray}{
~~~"беженец" n m aa pl acc
}

~\\
"<.>"\\
~~~"." sent
\end{alltt}
\end{tiny}
\end{columns}

\end{frame}

\begin{frame}{Rule application}


\end{frame}

\begin{frame}{Effort}

% Trosterud: 
% Huldén:
% Tyers (Breton)
% Tyers (Russian)
% Voutilainen:

\end{frame}

\begin{frame}{Cost / benefit}

%
%% no need for annotated corpus
%% more interesting than manually annotating a tonne of text

% 
%% problems with tagset changes


\end{frame}

\begin{frame}{Examples}

Languages with constraint grammars:
\begin{itemize}
  \item Finnish
  \item North Sámi, Lule Sámi, South Sámi
  \item Norwegian (Nynorsk, Bokmål)
  \item Faroese
  \item Udmurt
  \item Breton
\end{itemize}

\end{frame}

%% Rule-application

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HMM
\begin{frame}
\centering
{\LARGE {\bf HMM-based } }
\end{frame}

% generative model
\begin{frame}

% predict hidden states from observed states
% hidden states = sequence of part of speech tags
% observed states = ambiguity classes or surface forms

\end{frame}

% assumptions

% bigrams

\begin{frame}{Visible events}

% ambiguity classes
% surface forms

\end{frame}

% worked example

\begin{frame}{A tagged corpus}

\textbf{Analysed:} \\
\begin{tabular}{ll}
& Vino/NOUN/VERB a/ADP la/DET/PRON playa/NOUN ./PUNCT \\
& Voy/VERB a/ADP la/DET/PRON casa/NOUN/VERB ./PUNCT \\
& Bebe/VERB vino/NOUN/VERB en/ADP casa/NOUN/VERB ./PUNCT \\
& La/DET/PRON casa/NOUN/VERB es/VERB grande/ADJ ./PUNCT \\
& Es/VERB una/DET/PRON/VERB ciudad/NOUN grande/ADJ ./PUNCT \\
\end{tabular} 

\textbf{Tagged:} \\
\begin{tabular}{ll}
& Vino/VERB a/ADP la/DET playa/NOUN ./PUNCT \\
& Voy/VERB a/ADP la/DET casa/NOUN ./PUNCT \\
& Bebe/VERB vino/NOUN en/ADP casa/NOUN ./PUNCT \\
& La/DET casa/NOUN es/VERB grande/ADJ ./PUNCT \\
& Es/VERB una/DET ciudad/NOUN grande/ADJ ./PUNCT \\
\end{tabular}

\end{frame}

\begin{frame}{Transition probabilities}

We calculate the transition probabilities, $A$ from a matrix of transition counts:
\begin{center}
\begin{onlyenv}<1-3>
\begin{tabular}{lrrrrrrrr}
      & \multicolumn{7}{c}{Second tag} \\
      & VERB & NOUN & DET& PRON & ADP & ADJ & PUNCT  & \\
VERB  & \alert<3>{0}  & \alert<2-3>{1}  & \alert<3>{1}  & \alert<3>{0}  & \alert<3>{2}  & \alert<3>{1}  & \alert<3>{0}  & \\
NOUN  & 1  & 0  & 0  & 0  & 1  & 1  & 3  & \\
DET & 0  & 4  & 0  & 0  & 0  & 0  & 0  & \\
PRON  & 0  & 0  & 0  & 0  & 0  & 0  & 0  & \\
ADP & 0  & 1  & 2  & 0  & 0  & 0  & 0  & \\
ADJ  & 0  & 0  & 0  & 0  & 0  & 0  & 2  & \\
PUNCT  & 3  & 0  & 1  & 0  & 0  & 0  & 0   & \\
\end{tabular}
\end{onlyenv}
\begin{onlyenv}<4-5>
\begin{tabular}{lrrrrrrrr}
      & \multicolumn{7}{c}{Second tag} \\
      & VERB & NOUN & DET & PRON & ADP & ADJ & PUNCT  & \\
VERB  & 0  & 0.2  & 0.2  & 0  & 0.4  & 0.2  & 0  & \\
NOUN  & 0.16  & 0  & 0  & 0  & 0.16  & 0.16  & 0.5  & \\
DET  & 0  & 1  & 0  & 0  & 0  & 0  & 0  & \\
PRON  & 0  & 0  & 0  & 0  & 0  & 0  & 0  & \\
ADP  & 0  & 0.3  & 0.6  & 0  & 0  & 0  & 0  & \\
ADJ  & 0  & 0  & 0  & 0  & 0  & 0  & 1  & \\
\alert<5>{PUNCT}$^\dagger$  & 0.75  & 0  & 0.25  & 0  & 0  & 0  & 0   & \\
\end{tabular}
~\\
~\\
~\\
$\dagger$ This row represents the initial probabilities, $\pi$ of the model.

\end{onlyenv}
\end{center}


\end{frame}

\begin{frame}{A tagged corpus}

\textbf{Analysed:} \\
\begin{tabular}{ll}
& Vino/NOUN/VERB a/ADP la/DET/PRON playa/NOUN ./PUNCT \\
& Voy/VERB a/ADP la/DET/PRON casa/NOUN/VERB ./PUNCT \\
& Bebe/VERB vino/NOUN/VERB en/ADP casa/NOUN/VERB ./PUNCT \\
& La/DET/PRON casa/NOUN/VERB es/VERB grande/ADJ ./PUNCT \\
& Es/VERB una/DET/PRON/VERB ciudad/NOUN grande/ADJ ./PUNCT \\
\end{tabular} 

\textbf{Tagged:} \\
\begin{tabular}{ll}
& Vino/VERB a/ADP la/DET playa/NOUN ./PUNCT \\
& Voy/VERB a/ADP la/DET casa/NOUN ./PUNCT \\
& Bebe/VERB vino/NOUN en/ADP casa/NOUN ./PUNCT \\
& La/DET casa/NOUN es/VERB grande/ADJ ./PUNCT \\
& Es/VERB una/DET ciudad/NOUN grande/ADJ ./PUNCT \\
\end{tabular}

\end{frame}

\begin{frame}{Emission probabilities}

The probability of seeing an ambiguity class given a tag, $B$.

\begin{center}
\begin{onlyenv}<1>
\scalebox{0.9}{
\begin{tabular}{lrrrrrrrr}
                & VERB & NOUN & DET & PRON & ADP & ADJ & PUNCT & \\
ADJ             & 0    & 0    & 0    & 0 &  0 & 0 & 2 \\
DET/PRON        & 0    & 0    & 3    & 0 &  0 & 0 & 0 \\
DET/PRON/VERB   & 0    & 0    & 1    & 0 &  0 & 0 & 0 \\
NOUN            & 0    & 2    & 0    & 0 &  0 & 0 & 0 \\
NOUN/VERB       & 1    & 4    & 0    & 0 &  0 & 0 & 0 \\
ADP             & 0    & 0    & 0    & 0 &  3 & 0 & 0 \\
PUNCT           & 0    & 0    & 0    & 0 &  0 & 0 & 5 \\
VERB            & 4    & 0    & 0    & 0 &  0 & 0 & 0 \\
\hline
Total:          & 5    & 6    & 4    & 0 &  3 & 2 & 5 \\
\end{tabular}
}
\end{onlyenv}
\begin{onlyenv}<2>
\scalebox{0.9}{
\begin{tabular}{lrrrrrrrr}
                & VERB & NOUN & DET & PRON & ADP & ADJ & PUNCT & \\
ADJ             & 0    & 0    & 0    & 0 &  0 & 1.0 & 0 \\
DET/PRON        & 0    & 0    & 0.75 & 0 &  0 & 0 & 0 \\
DET/PRON/VERB   & 0    & 0    & 0.25 & 0 &  0 & 0 & 0 \\
NOUN            & 0    & 0.33 & 0    & 0 &  0 & 0 & 0 \\
NOUN/VERB       & 0.2  & 0.67 & 0    & 0 &  0 & 0 & 0 \\
ADP             & 0    & 0    & 0    & 0 &  1.0 & 0 & 0 \\
PUNCT           & 0    & 0    & 0    & 0 &  0 & 0 & 1.0 \\
VERB            & 0.8  & 0    & 0    & 0 &  0 & 0 & 0 \\
\end{tabular}
}
\end{onlyenv}
\end{center}
% The probability of seeing an ambiguity class given the tag.  

\end{frame}

% extensions

\begin{frame}{Viterbi}

\begin{onlyenv}<1>
\includegraphics[width=\textwidth]{images/viterbi-1.eps}
\end{onlyenv}

\begin{onlyenv}<2>
\includegraphics[width=\textwidth]{images/viterbi-2.eps}
\end{onlyenv}


\end{frame}


\begin{frame}{Decoding}

\begin{center}

\begin{onlyenv}<1>
  \emph{Vino a una casa grande.}
  %Vino<noun>/<verb> a<pr> una<det>/<prn>/<verb> casa<noun>/<verb> grande<adj> .<sent> 
  ~\\
  ~\\
  
  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$ &   &   &   &   &   &   &    \\
    \hline
    VERB &  &   &   &   &   &   &    \\
    \hline
    NOUN  &   &   &   &   &   &   &    \\
    \hline
    DET &   &   &   &   &   &   &    \\
    \hline
    PRON  &   &   &   &   &   &   &    \\
    \hline
    ADP &   &   &   &   &   &   &    \\
    \hline
    ADJ  &   &   &   &   &   &   &    \\
    \hline
    PUNCT  &   &   &   &   &   &   &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }
\end{onlyenv}
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<2>

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$ &   &   &   &   &   &   &    \\
    \hline
    VERB & 0.15, $q_0$ &   &   &   &   &   &    \\
    \hline
    NOUN  & 0.0, $q_0$ &   &   &   &   &   &    \\
    \hline
    DET &   &   &   &   &   &   &    \\
    \hline
    PRON  &   &   &   &   &   &   &    \\
    \hline
    ADP &   &   &   &   &   &   &    \\
    \hline
    ADJ  &   &   &   &   &   &   &    \\
    \hline
    PUNCT  &   &   &   &   &   &   &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }

{\small
\begin{itemize}
  \item = P(VERB,PUNCT) * P(VERB, VERB/NOUN) = 0.75 * 0.2 = 0.15
  \item = P(NOUN,PUNCT) * P(NOUN, VERB/NOUN) = 0.0 * 0.67 = 0.0
\end{itemize}
}

\end{onlyenv}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<3>

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$ &   &   &   &   &   &   &    \\
    \hline
    VERB & 0.15, $q_0$ &   &   &   &   &   &    \\
    \hline
    NOUN  & 0.0, $q_0$ &   &   &   &   &   &    \\
    \hline
    DET &   &   &   &   &   &   &    \\
    \hline
    PRON  &   &   &   &   &   &   &    \\
    \hline
    ADP &   & 0.06, VERB  &   &   &   &   &    \\
    \hline
    ADJ  &   &   &   &   &   &   &    \\
    \hline
    PUNCT  &   &   &   &   &   &   &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }

{\small
\begin{itemize}
  \item = P(ADP,VERB) * P(ADP, ADP) * P(PATH) = 0.4 * 1.0 * 0.15 = 0.06
  \item = P(ADP,NOUN) * P(ADP, ADP) * P(PATH) = 0.16 * 1.0 * 0.0 = 0
\end{itemize}
}

\end{onlyenv}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<4>

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$   &             &             &   &   &   &   &    \\
    \hline
    VERB    & 0.15, $q_0$ &             & 0.0, ADP  &   &   &   &    \\
    \hline
    NOUN    & 0.0, $q_0$  &             &   &   &   &   &    \\
    \hline
    DET     &             &             & 0.009, ADP   &   &   &   &    \\
    \hline
    PRON    &             &             & 0.0, ADP  &   &   &   &    \\
    \hline
    ADP     &             & 0.06, VERB  &   &   &   &   &    \\
    \hline
    ADJ     &             &             &   &   &   &   &    \\
    \hline
    PUNCT   &             &             &   &   &   &   &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }

{\tiny
\begin{itemize}
  \item = P(DET,ADP) * P(DET, DET/PRON/VERB) * P(PATH) = 0.6 * 0.25 * 0.06 = 0.009
  \item = P(PRON,ADP) * P(PRON, DET/PRON/VERB) * P(PATH) = 0.0 * 0.0 * 0.06 = 0.0
  \item = P(VERB,ADP) * P(VERB, DET/PRON/VERB) * P(PATH) = 0.0 * 0.0 * 0.06 = 0.0
\end{itemize}
}

\end{onlyenv}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<5>

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$   &             &             &   &   &   &   &    \\
    \hline
    VERB    & 0.15, $q_0$ &             & 0.0, ADP  & 0.0, DET*  &   &   &    \\
    \hline
    NOUN    & 0.0, $q_0$  &             &           & 0.006, DET   &   &  &    \\
    \hline
    DET     &             &             & 0.009, ADP   &   &   &   &    \\
    \hline
    PRON    &             &             & 0.0, ADP  &   &   &   &    \\
    \hline
    ADP     &             & 0.06, VERB  &   &   &   &   &    \\
    \hline
    ADJ     &             &             &   &   &   &   &    \\
    \hline
    PUNCT   &             &             &   &   &   &   &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }

{\tiny
\begin{itemize}
  \item = P(NOUN,VERB) * P(NOUN, NOUN/VERB) * P(PATH) = 0.2 * 0.67 * 0.009 = 0.001
  \item = P(VERB,VERB) * P(VERB, NOUN/VERB) * P(PATH) = 0.0 * 0.2  * 0.009 = 0.0
  \item = P(NOUN,DET) * P(NOUN, NOUN/VERB) * P(PATH) =  1.0 * 0.67 * 0.009 = 0.006
  \item = P(VERB,DET) * P(VERB, NOUN/VERB) * P(PATH) =  0.0 * 0.2  * 0.009 = 0.0
  \item = P(NOUN,PRON) * P(NOUN, NOUN/VERB) * P(PATH) = 0.0 * 0.67 * 0.009 = 0.0 
  \item = P(VERB,PRON) * P(VERB, NOUN/VERB) * P(PATH) = 0.0 * 0.67 * 0.009 = 0.0
\end{itemize}
}

\end{onlyenv}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<6>

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$   &             &             &   &   &   &   &    \\
    \hline
    VERB    & 0.15, $q_0$ &             & 0.0, ADP  & 0.0, DET*  &   &   &    \\
    \hline
    NOUN    & 0.0, $q_0$  &             &           & 0.006, DET   &   &  &    \\
    \hline
    DET     &             &             & 0.009, ADP   &   &   &   &    \\
    \hline
    PRON    &             &             & 0.0, ADP  &   &   &   &    \\
    \hline
    ADP     &             & 0.06, VERB  &   &   &   &   &    \\
    \hline
    ADJ     &             &             &   &   &    0.001, NOUN &  &    \\
    \hline
    PUNCT   &             &             &   &   &   &   &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }

{\tiny
\begin{itemize}
  \item = P(ADJ,NOUN) * P(ADJ, ADJ) * P(PATH) = 0.16 * 1.0 * 0.006 = 0.00096
  \item = P(ADJ,VERB) * P(ADJ, ADJ) * P(PATH) = 0.2 * 1.0 * 0.0 = 0.0
\end{itemize}
}

\end{onlyenv}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<7>

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$   &             &             &   &   &   &   &    \\
    \hline
    VERB    & 0.15, $q_0$ &             & 0.0, ADP  & 0.0, DET*  &   &   &    \\
    \hline
    NOUN    & 0.0, $q_0$  &             &           & 0.006, DET   &   &  &    \\
    \hline
    DET     &             &             & 0.009, ADP   &   &   &   &    \\
    \hline
    PRON    &             &             & 0.0, ADP  &   &   &   &    \\
    \hline
    ADP     &             & 0.06, VERB  &   &   &   &   &    \\
    \hline
    ADJ     &             &             &   &   &    0.001, NOUN &  &    \\
    \hline
    PUNCT   &             &             &   &   &   & 0.001, ADJ  &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }

{\tiny
\begin{itemize}
  \item = P(PUNCT,ADJ) * P(PUNCT, PUNCT) * P(PATH) = 1.0 * 1.0 * 0.001 = 0.001
\end{itemize}
}

\end{onlyenv}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{onlyenv}<8->

  \scalebox{0.7}{
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
           \multicolumn{8}{c}{{\large $\rightarrow$}}  \\
    \hline
    $q_F$   &             &             &   &   &   &   &    \\
    \hline
    VERB    & 0.15, \alert<14>{$q_0$} &             & 0.0, ADP  & 0.0, DET*  &   &   &    \\
    \hline
    NOUN    & 0.0, $q_0$  &             &           & 0.006, \alert<11>{DET}   &   &  &    \\
    \hline
    DET     &             &             & 0.009, \alert<12>{ADP}   &   &   &   &    \\
    \hline
    PRON    &             &             & 0.0, ADP  &   &   &   &    \\
    \hline
    ADP     &             & 0.06, \alert<13>{VERB}  &   &   &   &   &    \\
    \hline
    ADJ     &             &             &   &   &    0.001, \alert<10>{NOUN} &  &    \\
    \hline
    PUNCT   &             &             &   &   &   & 0.001, \alert<9>{ADJ}  &   \\
    \hline
          & VERB/NOUN & ADP & DET/PRON/VERB & NOUN/VERB & ADJ & PUNCT & \\
    \hline
          & \emph{Vino} & \emph{a} & \emph{una} & \emph{casa} & \emph{grande} & . & \\
    \hline
    \end{tabular}
  }
\end{onlyenv}

\begin{onlyenv}<8>
PUNCT
\end{onlyenv}
\begin{onlyenv}<9>
ADJ PUNCT
\end{onlyenv}
\begin{onlyenv}<10>
NOUN ADJ PUNCT
\end{onlyenv}
\begin{onlyenv}<11>
DET NOUN ADJ PUNCT
\end{onlyenv}
\begin{onlyenv}<12>
ADP DET NOUN ADJ PUNCT
\end{onlyenv}
\begin{onlyenv}<13->
VERB ADP DET NOUN ADJ PUNCT
\end{onlyenv}

\end{center}


% step 1: PUNCT VERB = p(verb,punct) = 0.75 * 0.2 || PUNCT NOUN = p(noun,punct) = 0 * 0.67 = 0

\end{frame}

\begin{frame}{Implementation}


\end{frame}

\begin{frame}{Extensions}

\begin{itemize}
  \item Trigrams
  \item Backoff 
  \item Unknown words
  \item Capitalisation
\end{itemize}

% downsides
% Hard to add new features

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Averaged Perceptron
\begin{frame}
\centering
{\LARGE {\bf Averaged perceptron} }
\end{frame}

\begin{frame}
% discriminative model
% beautifully simple

\end{frame}

\begin{frame}{Training}

\begin{center}
\includegraphics[width=\textwidth]{images/perceptron-train.png}
\end{center}


% loop
% averaging
% training from predictions

\end{frame}

\begin{frame}{Features}

%    add('i suffix', word[-3:])
%    add('i pref1', word[0])
%    add('i-1 tag', prev)
%    add('i-2 tag', prev2)
%    add('i tag+i-2 tag', prev, prev2)
%    add('i word', context[i])
%    add('i-1 tag+i word', prev, context[i])
%    add('i-1 word', context[i-1])
%    add('i-1 suffix', context[i-1][-3:])
%    add('i-2 word', context[i-2])
%    add('i+1 word', context[i+1])
%    add('i+1 suffix', context[i+1][-3:])
%    add('i+2 word', context[i+2])

\begin{center}
\begin{tabular}{llllll}
Vino & a & una & casa & grande & . \\
$i-2$ & $i-1$ & $i$ & $i+1$ & $i+2$ & $i+3$ \\
\end{tabular}
\end{center} 
~\\
\scalebox{0.9}{
  \centering
  \begin{tabular}{lll}
  $i$  & Trigram suffix  & una \\
  $i$  & Unigram prefix  & u \\
  $i-1$ & Tag & ADP \\
  $i-2$ & Tag & VERB \\
  %  Tag $i$ + tag $i-2$ & &  \\
  $i$ &  Word  & una \\
  $i-1$, $i$ &  Tag, Word  & ADP + una \\
  $i-1$ & Word & a \\
  $i-1$ & Trigram suffix & a \\
  $i-2$ & Word & Vino \\
  $i+1$ & Word  & casa \\
  $i+1$ & Trigram suffix  & asa \\
  $i+2$ &  Word  & grande \\
  \end{tabular}
}


\end{frame}

\begin{frame}{Averaging}

\end{frame}

\begin{frame}{Dictionary}


\end{frame}

\begin{frame}{Prediction}

\begin{center}
\includegraphics[width=\textwidth]{images/perceptron-predict.png}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Comparison of approaches}

% CG -- can start from scratch, but tagsets can be a problem
% HMM -- can make n-best list
% perceptron -- more robust, easier to add features to

% all taggers report around 97% accuracy [refs]
% getting beyond 97% ?
%% Chris Manning (2011) "Part-of-Speech Tagging from 97% to 100%: Is It Time for Some Linguistics?"

%\includegraphics[width=\textwidth]{images/manning-errors.png}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% How much data ?

\begin{frame}{How much data ?}

\end{frame}

\begin{frame}{Time comparison}

% annotation time vs. rule-writing time

% Huldén 20 hours / 148 rules / 113 generic, 35 for wordforms [working from a devel. corpus]
% Tyers 1 month / 299 rules [working from nothing]

% 8000--10000 tokens/month = ~50-60 tokens/hour

\end{frame}

% Combination/voting

\begin{frame}{Tagger combination}



\end{frame}


\begin{frame}{Some taggers}
% some state of the art systems

% specifically for russian:
% pymorphy

% trainable:
% hunpos
% udpipe
% marmot


\end{frame}

% error analysis: http://machinelearningtext.pbworks.com/w/file/fetch/48157747/CICLing2011-manning-tagging.pdf

%\begin{frame}
 
%\end{frame}

\begin{frame}{Practicals}

\begin{itemize}
  \item \textbf{Tagger comparison}:
  \begin{itemize}
     \item Compare three taggers on a language of your choice
  \end{itemize}
  \item \textbf{Constraint grammar}: 
  \begin{itemize}
     \item Select a small text (500 tokens) in a language of your choice
     \item Analyse it with a morphological analyser
     \item Resolve as much of the ambiguity as you can
  \end{itemize}
  \item \textbf{Perceptron tagger}:
  \begin{itemize}
     \item Download \url{https://github.com/ftyers/conllu-perceptron-tagger}
     \item Run it on a language from Universal Dependencies
     \item Improve it so that you get better performance
     \begin{itemize}
       \item Add support for morphological features
       \item Try tweaking other features
     \end{itemize}
  \end{itemize}
\end{itemize}

\end{frame}

\end{document}
